{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "jax.device_count(), jax.devices()[0].device_kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper_stream import load_data_samples_from_path\n",
    "from whisper_stream.pipelines import (\n",
    "    JAXStreamablePipeline,\n",
    "    JAXValidDtypesMapping,\n",
    "    JAXScalarDType,\n",
    "    JAXCheckpoints,\n",
    "    JAXValidTasks,\n",
    ")\n",
    "from whisper_stream.logger import LOG_LEVEL_NAMES\n",
    "import time\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint: JAXCheckpoints = \"openai/whisper-tiny\"\n",
    "model_dtype: JAXScalarDType = JAXValidDtypesMapping[\"BFLOAT16\"]\n",
    "task: JAXValidTasks = \"transcribe\"\n",
    "language: str = \"english\"\n",
    "return_timestamps: bool = True\n",
    "batch_size: int = 32\n",
    "log_level: LOG_LEVEL_NAMES = \"INFO\"\n",
    "\n",
    "run_opts = {\"batch_size\": batch_size, \"return_timestamps\": return_timestamps, \"language\": language, \"task\": task}\n",
    "\n",
    "# construct\n",
    "pipeline = JAXStreamablePipeline(\n",
    "    checkpoint=checkpoint, dtype=model_dtype, batch_size=batch_size, min_log_level=log_level\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "pipeline_data: bytes = load_data_samples_from_path(\"audio_1.mp3\", binary_mode=True)  # 4s\n",
    "pipeline_data_large: bytes = load_data_samples_from_path(\"tryst.mp3\", binary_mode=True)  # 4:44s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize & warmup\n",
    "%time pipeline.initialize_pipeline(**run_opts, use_experimental_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be warmed up now (time should be similar to # small data)\n",
    "%time list(pipeline(pipeline_data, **run_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small data\n",
    "%time list(pipeline(pipeline_data, **run_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small data in batch\n",
    "%time list(pipeline([pipeline_data] * 10, **run_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunkable data\n",
    "%time list(pipeline(pipeline_data_large, **run_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunkable data in batches\n",
    "%time list(pipeline([pipeline_data_large] * 32, **run_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_mode_data: list[bytes] = [pipeline_data_large, pipeline_data, pipeline_data, pipeline_data] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed data, received as it comes, using default `smallest` strategy the smaller files will come in larger batches first\n",
    "start: float = time.time()\n",
    "for data in pipeline(mixed_mode_data, strategy=\"smallest\", **run_opts):\n",
    "    print({\"num_items\": len(data)}, end=\"\\n\")\n",
    "    print({\"data\": data, \"time_taken\": f\"{time.time() - start:.2}s\"}, end=\"\\n\")\n",
    "    print(\"-\" * 40, end=\"\\n\")\n",
    "    start = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
